import asyncio
import feedparser
import requests
import re
import random
from datetime import datetime, timedelta
from aiogram import Bot, Dispatcher
from aiogram.utils.markdown import hbold
from aiogram.enums.parse_mode import ParseMode
from aiogram.client.default import DefaultBotProperties

# üîë –í—Å—Ç–∞–≤—å —Å–≤–æ–∏ –∫–ª—é—á–∏
TOKEN = "7918775198:AAFCYlnMQMed_GDo0HXBnRPxTrGB-IhaGnY"
CHANNEL_ID = "@newspoliticcccals"

# üì° –¢–æ–ª—å–∫–æ —É–∫—Ä–∞–∏–Ω–æ—è–∑—ã—á–Ω—ã–µ –∏ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏-–≤–æ–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
RSS_FEEDS = [
    "https://censor.net/rss/all.xml",
    "https://glavcom.ua/rss/all.xml",
    "https://focus.ua/rss/all.xml",
    "https://telegraf.com.ua/rss.xml",
    "https://www.pravda.com.ua/rss/view_news/",
    "https://tsn.ua/rss/full.rss",
    "https://24tv.ua/rss/all.xml",
    "https://rss.unian.net/site/news_ukr.rss",
    "https://news.liga.net/news/rss.xml",
]

# ‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()

# üß† –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å
posted_links = set()


def clean_html(text):
    """üßπ–£–¥–∞–ª—è–µ—Ç HTML-—Ç–µ–≥–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç"""
    return re.sub(r"<[^>]+>", "", text)


async def fetch_news():
    """üì¨ –ü—É–±–ª–∏–∫—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫"""
    global posted_links
    while True:
        now = datetime.now()
        current_hour = now.hour

        if 0 <= current_hour < 7:
            num_posts = 3
            interval_minutes = 60  # –Ω–∞ 7 —á–∞—Å–æ–≤ ‚Äî –ø–æ—Å—Ç—ã –≤ —Å—Ä–µ–¥–Ω–µ–º –∫–∞–∂–¥—ã–µ ~2 —á–∞—Å–∞
            period_minutes = 420   # 7 —á–∞—Å–æ–≤ * 60 –º–∏–Ω
        else:
            num_posts = 4
            interval_minutes = 60  # –∫–∞–∂–¥—ã–π —á–∞—Å
            period_minutes = 60

        try:
            news_posts = []
            for feed_url in RSS_FEEDS:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries[:3]:  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                    title = entry.title
                    link = entry.link
                    summary = entry.summary if hasattr(entry, "summary") else "–ù–µ–º–∞—î –æ–ø–∏—Å—É"
                    summary = clean_html(summary)

                    if link in posted_links:
                        continue

                    post_text = f"üì∞ <b>{hbold(title)}</b>\n\n{summary}\n\nüîó <a href='{link}'>–ß–∏—Ç–∞—Ç–∏ –ø–æ–≤–Ω—ñ—Å—Ç—é</a>"
                    news_posts.append(post_text)
                    posted_links.add(link)

            if news_posts:
                selected_posts = random.sample(news_posts, min(num_posts, len(news_posts)))
                post_times = sorted([now + timedelta(minutes=random.randint(1, interval_minutes))
                                     for _ in range(len(selected_posts))])

                for post_text, post_time in zip(selected_posts, post_times):
                    wait_time = (post_time - datetime.now()).total_seconds()
                    print(f"‚è± –û—á—ñ–∫—É–≤–∞–Ω–Ω—è –¥–æ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó: {wait_time // 60:.0f} —Ö–≤ ({post_time.strftime('%H:%M')})")
                    await asyncio.sleep(wait_time)
                    await bot.send_message(CHANNEL_ID, post_text)

            print("‚úÖ –ù–æ–≤–∏–Ω–∏ –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω—ñ. –ß–µ–∫–∞—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –ø–µ—Ä—ñ–æ–¥—É.")
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó –Ω–æ–≤–∏–Ω: {e}")

        await asyncio.sleep(period_minutes * 60)


async def main():
    """üöÄ –ó–∞–ø—É—Å–∫–∞—î –ø—Ä–æ—Ü–µ—Å –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó –Ω–æ–≤–∏–Ω"""
    await fetch_news()


if __name__ == "__main__":
    asyncio.run(main())

